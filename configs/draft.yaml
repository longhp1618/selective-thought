
run_name: 'dpo-1'
output_dir: '/home/long/long/code/selective-thought/saved_models/dpo-1'
overwrite_output_dir: true
bf16: true
tf32: true
report_to: 'none' #'wandb'
seed: 42
per_device_train_batch_size: 1
gradient_accumulation_steps: 32
# max_steps: 100
# num_epochs: 1
optim: 'adamw_torch'
weight_decay: 0.01
lr_scheduler_type: 'cosine_with_min_lr'
learning_rate: 3e-7
lr_scheduler_kwargs:
  min_lr_rate: 0.1
warmup_ratio: 0.1
save_strategy: 'no'
ddp_find_unused_parameters: false
dataloader_num_workers: 12
beta: 0.1
max_prompt_length: 256
max_length: 1792
logging_steps: 5
remove_unused_columns: False

num_train_epochs: 1
# max_seq_length: 4096