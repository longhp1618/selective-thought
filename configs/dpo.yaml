
run_name: 'dpo-math'
output_dir: 'saved_models/math/dpo'
overwrite_output_dir: true
bf16: true
tf32: true
report_to: 'none' #'wandb'
seed: 42
per_device_train_batch_size: 1
gradient_accumulation_steps: 32
# max_steps: 100
# num_epochs: 1
optim: 'adamw_torch'
weight_decay: 0.01
lr_scheduler_type: 'cosine_with_min_lr'
learning_rate: 1e-7
lr_scheduler_kwargs:
  min_lr_rate: 0.1
warmup_ratio: 0.1
save_strategy: 'no'
ddp_find_unused_parameters: false
dataloader_num_workers: 0
beta: 0.1
max_prompt_length: 256
max_length: 4096
logging_steps: 5
remove_unused_columns: False

num_train_epochs: 5
# max_seq_length: 4096